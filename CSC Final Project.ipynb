{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fc683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numba import jit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve, ShuffleSplit\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB, BernoulliNB \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score , classification_report, ConfusionMatrixDisplay,precision_score,recall_score, f1_score,roc_auc_score,roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a34e8c",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION FROM RESEARCHERS DEPLOYING VORACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa4abe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:269: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if tiebreak is \"best\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:272: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:307: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:325: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Plurality':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:328: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'HalfApproval':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:335: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Borda':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:424: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Copeland':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:427: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Sum\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:433: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Mean\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:439: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Kemeny\":\n",
      "2023-04-10 14:44:56.032337: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-10 14:44:56.158040: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-10 14:44:56.158739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 14:44:56.756760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-10 14:44:57.892123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-10 14:44:57.999340: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:269: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if tiebreak is \"best\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:272: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:307: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:325: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Plurality':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:328: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'HalfApproval':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:335: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Borda':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:424: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Copeland':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:427: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Sum\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:433: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Mean\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:439: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Kemeny\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:269: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if tiebreak is \"best\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:272: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:307: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:325: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Plurality':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:328: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'HalfApproval':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:335: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Borda':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:424: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Copeland':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:427: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Sum\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:433: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Mean\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:439: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Kemeny\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:269: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if tiebreak is \"best\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:272: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:307: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:325: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Plurality':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:328: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'HalfApproval':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:335: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Borda':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:424: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Copeland':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:427: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Sum\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:433: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Mean\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:439: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Kemeny\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:269: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if tiebreak is \"best\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:272: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:307: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if voting is \"Plurality\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:325: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Plurality':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:328: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'HalfApproval':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:335: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Borda':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:424: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if scoring is 'Copeland':\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:427: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Sum\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:433: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Mean\":\n",
      "/home/potatosalad/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:439: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif scoring is \"Kemeny\":\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m y_train\n\u001b[1;32m     29\u001b[0m y_oneHot_test\u001b[38;5;241m=\u001b[39mto_categorical(y_test,num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mvorace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_oneHot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbagging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m y_pred_vorace,_ \u001b[38;5;241m=\u001b[39m vorace\u001b[38;5;241m.\u001b[39mpredict(voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlurality\u001b[39m\u001b[38;5;124m\"\u001b[39m,x\u001b[38;5;241m=\u001b[39mX_test, nClasses\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, argMax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tiebreak\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred_vorace)\n",
      "File \u001b[0;32m~/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:229\u001b[0m, in \u001b[0;36mVorace.fit\u001b[0;34m(self, x, y, y_oneHot, bagging)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels)):\n\u001b[0;32m--> 229\u001b[0m \t\ttmp_hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_oneHot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m\t\t\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\t\tCompute accuracy to store weights\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m\t\t'''\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \t\t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[i])\u001b[38;5;241m==\u001b[39mModel:\n",
      "File \u001b[0;32m~/Documents/RUG/Msc/2A/CSC_homework_3_group4/Vorace.py:124\u001b[0m, in \u001b[0;36mVorace_agent.fit\u001b[0;34m(self, x, y, y_oneHot)\u001b[0m\n\u001b[1;32m    122\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m \t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \ty_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mpredict(x)\n\u001b[1;32m    126\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m  metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y,y_pred)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filey87udks_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/potatosalad/.local/share/virtualenvs/CSC_homework_3_group4-nat9sqnt/lib/python3.10/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# data: https://archive.ics.uci.edu/ml/datasets.php\n",
    "# VORACE: https://github.com/aloreggia/vorace/blob/main/src/vorace_test.ipynb\n",
    "# https://pypi.org/project/corankco/1.0.0/ -> package has newer version, namely 4.0.0 that brakes current Vorace implementation\n",
    "\n",
    "\"\"\" Example using VORACE from researchers repo \"\"\"\n",
    "from Vorace import Vorace\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "df = load_iris(return_X_y=True)\n",
    "vorace = Vorace(n_models=10, profile_type=3, nInput=4, nClasses=3, batch_size=16)\n",
    "\n",
    "X = df[0]\n",
    "y = df[1]\n",
    "y = np.asarray(y)\n",
    "y=y.reshape(-1,)\n",
    "y_oneHot=to_categorical(y,num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_oneHot=to_categorical(y_train,num_classes=3)\n",
    "y_train\n",
    " \n",
    "y_oneHot_test=to_categorical(y_test,num_classes=3)\n",
    "\n",
    "vorace.fit(X_train, y_train, y_oneHot, bagging=False)\n",
    "\n",
    "y_pred_vorace,_ = vorace.predict(voting=\"Plurality\",x=X_test, nClasses=3, argMax=True, tiebreak=\"best\")\n",
    "print(y_pred_vorace)\n",
    "print(y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_vorace)\n",
    "print(accuracy)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred_vorace)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41f519",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf88e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = True\n",
    "\n",
    "def fit_models(X, Y, X_t, Y_t, models, params, run=\"\", folder=\"\"):\n",
    "    \n",
    "    if folder == \"\":\n",
    "        raise Exception(\"Please provide a folder...\")\n",
    "        \n",
    "    \n",
    "    print(\"Fitting models...\")\n",
    "     \n",
    "    @jit(target_backend='cuda')\n",
    "    def results(X,Y,model_name, model, data_type):\n",
    "        model_accuracy = accuracy_score(Y, model.predict(X)) \n",
    "        model_f1 = f1_score(Y, model.predict(X), average='weighted') \n",
    "        model_precision = precision_score(Y, model.predict(X),average='weighted') \n",
    "        model_recall = recall_score(Y, model.predict(X),average='weighted')\n",
    "\n",
    "        print('Model performance for ' + data_type + ' ' + model_name)\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_accuracy))\n",
    "        print('- F1 score: {:4f}'.format(model_f1))\n",
    "        print('- Precision: {:4f}'.format(model_precision))\n",
    "        print('- Recall: {:4f}'.format(model_recall))\n",
    "\n",
    "        print('----------------------------------')\n",
    "        print('='*35)\n",
    "        \n",
    "        if write:\n",
    "            if os.path.isfile(\"../models/\" + folder + \"/summaries/\" + model_name + \".txt\"):\n",
    "                f = open(\"../models/\" + folder + \"/summaries/\" + model_name + \".txt\", 'a')\n",
    "            else:\n",
    "                f = open(\"../models/\" + folder + \"/summaries/\" + model_name + \".txt\", 'w')\n",
    "\n",
    "            f.write(\"Model performance for \" + data_type + \" \" + model_name + \"\\n\")\n",
    "            f.write(\"- Accuracy: \" + str(round(model_accuracy,4)) + \"\\n\")\n",
    "            f.write(\"- F1 score: \" + str(round(model_f1,4)) + \"\\n\")\n",
    "            f.write(\"- Precision: \" + str(round(model_precision,4)) + \"\\n\")\n",
    "            f.write(\"- Recall: \" + str(round(model_recall,4)) + \"\\n\")\n",
    "\n",
    "            f.write('----------------------------------\\n')\n",
    "            f.write('='*35 + \"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    @jit(target_backend='cuda')\n",
    "    def cudafit(model, X, Y):\n",
    "\n",
    "        model.fit(X,Y)\n",
    "        return model\n",
    "\n",
    "    # @jit(target_backend='cuda') # RocCurveDisplay has not been included in JIT yet.\n",
    "    def plots(model, X, Y, X_t, Y_t, name):\n",
    "        RocCurveDisplay.from_estimator(model, X_t, Y_t, ax=ax[0][1])\n",
    "        _ = ax[0][1].set_title(\n",
    "            f\"ROC curve on test set for {name}\"\n",
    "        )\n",
    "\n",
    "        ConfusionMatrixDisplay.from_estimator(model, X, Y, ax=ax[1][0])\n",
    "        _ = ax[1][0].set_title(\n",
    "            f\"Confusion Matrix on train set for {name}\"\n",
    "        )\n",
    "\n",
    "        ConfusionMatrixDisplay.from_estimator(model, X_t, Y_t, ax=ax[1][1])\n",
    "        _ = ax[1][1].set_title(\n",
    "            f\"Confusion Matrix on test set for {name}\"\n",
    "        )\n",
    "\n",
    "    params_plot = {\n",
    "        \"X\": X,\n",
    "        \"y\": Y,\n",
    "        \"score_type\": \"both\",\n",
    "        \"n_jobs\": -2,\n",
    "        \"line_kw\": {\"marker\": \"o\"},\n",
    "        \"std_display_style\": \"fill_between\",\n",
    "        \"score_name\": \"accuracy\"\n",
    "    }\n",
    "    \n",
    "    dic_models = {}\n",
    "    models_ensemble = []\n",
    "    for i in range(len(list(models))):\n",
    "        models_ensemble.append((list(models.keys())[i], list(models.values())[i]))\n",
    "        dic_models[list(models.keys())[i]] = list(models.values())[i]\n",
    "\n",
    "    for i in range(len(list(models))):\n",
    "        print(list(models.keys())[i] + \"\\n\")\n",
    "        print(\"#\"*50)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "        model = make_pipeline(StandardScaler(), GridSearchCV(list(models.values())[i], list(params.values())[i],\n",
    "                           scoring='accuracy', refit=True, n_jobs=-2))\n",
    "\n",
    "        LearningCurveDisplay.from_estimator(model, **params_plot, ax=ax[0][0])\n",
    "        handles, label = ax[0][0].get_legend_handles_labels()\n",
    "        ax[0][0].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "        ax[0][0].set_title(f\"Learning Curve for {list(models.keys())[i]}\")\n",
    "\n",
    "        model = cudafit(model, X, Y)\n",
    "        if write:\n",
    "            dump(model, \"../models/\" + folder + \"/\" + run + \"_\" + list(models.keys())[i] + \".joblib\")\n",
    "\n",
    "        plots(model, X, Y, X_t, Y_t, list(models.keys())[i])\n",
    "\n",
    "        fig.tight_layout()\n",
    "        if write:\n",
    "            plt.savefig(\"../models/\" + folder +  \"/result_images/\" + run + \"_\" + list(models.keys())[i] + \".png\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "        plt.show()\n",
    "\n",
    "        # b_params = model.named_steps[\"clf\"].best_params_\n",
    "        # print(f'Best parameters: {b_params}\\n')\n",
    "        results(X,Y, list(models.keys())[i] + \"_\" + run, model, \"Training set\")\n",
    "        results(X_t,Y_t, list(models.keys())[i] + \"_\" + run, model, \"Test set\")\n",
    "        # results(Y_v,Y_validation_pred, list(models.keys())[i], list(models.values())[i], \"Validation set after optimization\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"################################################\")\n",
    "    print(\"################### ENSEMBLE ###################\")\n",
    "\n",
    "    dic_models[\"ensemble\"] = VotingClassifier(models_ensemble, voting='soft', n_jobs=-2, verbose=True)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "    LearningCurveDisplay.from_estimator(dic_models[\"ensemble\"], **params_plot, ax=ax[0][0])\n",
    "    handles, label = ax[0][0].get_legend_handles_labels()\n",
    "    ax[0][0].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[0][0].set_title(f\"Learning Curve for ENSEMBLE\")\n",
    "\n",
    "    dic_models[\"ensemble\"] = cudafit(dic_models[\"ensemble\"], X, Y)\n",
    "\n",
    "    results(X, Y, \"ENSEMBLE\"  + \"_\" + run, dic_models[\"ensemble\"], \"train set\")\n",
    "    results(X_t, Y_t, \"ENSEMBLE\"  + \"_\" + run, dic_models[\"ensemble\"], \"test set\")\n",
    "    \n",
    "    plots(dic_models[\"ensemble\"], X, Y, X_t, Y_t, \"ENSEMBLE\")\n",
    "    if write:\n",
    "        dump(dic_models[\"ensemble\"], \"../models/\" + folder + \"/\" + run + \"_\" + \"ensembler.joblib\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if write:\n",
    "        plt.savefig(\"../models/\" + folder + \"/result_images/\" + run + \"_\" + \"ensembler.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d022868",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\"      :LogisticRegression(),\n",
    "    \"Decision Tree\"            :DecisionTreeClassifier(),\n",
    "    \"Random Forest\"            :RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\"        :GradientBoostingClassifier(),\n",
    "    \"K-Nearest Neighbors\"      :KNeighborsClassifier(),\n",
    "    \"SVM\"                      :svm.SVC(probability=True)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Logistic Regression\"     :{\n",
    "        'solver': ['newton-cholesky', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "        'penalty':['l2'],\n",
    "        'C':[0.001, 0.01, 0.1, 1, 100],\n",
    "        'max_iter':[10000],\n",
    "    },\n",
    "    \"Decision Tree\"            :{\n",
    "        'criterion':['gini','entropy'],\n",
    "        'max_depth':[4,6,8,10,15,50,90]\n",
    "    },\n",
    "    \"Random Forest\"            :{ \n",
    "        'n_estimators': [200, 500],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "        'max_depth' : [4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy']\n",
    "    },\n",
    "    \"Gradient Boosting\"        :{\n",
    "        \"loss\":[\"log_loss\"],\n",
    "        \"learning_rate\": [0.1, 0.01],\n",
    "        \"max_depth\":[3,5,8],\n",
    "        \"max_features\":[\"log2\",\"sqrt\"],\n",
    "        \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "        \"subsample\":[0.5, 0.8, 1.0],\n",
    "        \"n_estimators\":[10, 100, 1000]\n",
    "    },\n",
    "    \"K-Nearest Neighbors\"      :{\n",
    "         'weights': ['uniform', 'distance'],'leaf_size': [5, 15, 25]\n",
    "    },\n",
    "    \"SVM\"                      :{\n",
    "    \"kernel\":['rbf'], \"C\":[0.1, 1, 10, 100, 1000], \"degree\":[1,5], \n",
    "        'gamma': [1, 0.1, 0.01, 0.001]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4647b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Amount of compounds per recipe \"\"\"\n",
    "df = \n",
    "X_ = \n",
    "Y_ = \n",
    "\n",
    "X, X_t, Y, Y_t = train_test_split(X_, Y_, test_size=0.20, random_state=42, shuffle=True)\n",
    "fit_models(X, Y, X_t, Y_t, models, params, \"RUN_NAME\", \"FOLDER_NAME\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC_homework_3_group4",
   "language": "python",
   "name": "csc_homework_3_group4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
